{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "293756ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7b3d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nishi\n",
      "[nltk_data]     Kapadia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nishi\n",
      "[nltk_data]     Kapadia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82b414eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In The Simpsons Movie released in July 2007 na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: professional logo for you now  workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: get your babies diapers bill paid for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: very uuseful  attache how to save on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: model effort in houston  christian , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>Get the official ENGLAND poly ringtone or colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>Subject: perfect logo charset = koi 8 - r \" &gt; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>Subject: save your money by getting an oem sof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>Dear where you. Call me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>Subject: logo , stationer , website design and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2885 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text\n",
       "0     In The Simpsons Movie released in July 2007 na...\n",
       "1     Subject: professional logo for you now  workin...\n",
       "2     Subject: get your babies diapers bill paid for...\n",
       "3     Subject: very uuseful  attache how to save on ...\n",
       "4     Subject: model effort in houston  christian , ...\n",
       "...                                                 ...\n",
       "2880  Get the official ENGLAND poly ringtone or colo...\n",
       "2881  Subject: perfect logo charset = koi 8 - r \" > ...\n",
       "2882  Subject: save your money by getting an oem sof...\n",
       "2883                            Dear where you. Call me\n",
       "2884  Subject: logo , stationer , website design and...\n",
       "\n",
       "[2885 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the excel data\n",
    "df = pd.read_excel(r\"C:\\College\\sem6\\NLP\\project\\text_dataset.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41132416",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b454d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2885 entries, 0 to 2884\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    2885 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 22.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654bbb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values and remove\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fbd9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2790, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values and remove\n",
    "print(df.duplicated().sum())\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b12c43",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "680f4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishi Kapadia\\AppData\\Local\\Temp\\ipykernel_20240\\3520636091.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Text'] = df['Text'].str.replace(letter, '')\n"
     ]
    }
   ],
   "source": [
    "# replace unnecessary letters/words\n",
    "replace_list = [\"\\\\n\",\"\\\\t\",\"\\\\r\",\"â\",\"€\",\"™\",\"ð\",\"Ÿ\",\"ðŸ‘\",\"$\",\"â€™ll\",\"ƒ\",\"¢\",\"â€ƒ\",\"â€¢\",\"Â§\",\"§\",\"Â\",\"Ã¼\",\"Ã\",\"¼\",\"º\",\"œ\",\"˜\",\"£\",\"â€“\",\"â€œ\",\"&lt;#&gt;\",\"â€Œ\",\"ðŸŽ\",\"ð\",\"Ÿ\",\"Ž\",\"Í\",\"â€Œ ï»¿ Í\",\"ï»¿\",\"ðŸ”¨\",\"ðŸ¤©\",\"©\",\"¤\",\"±\",\"ðŸ˜±\",\"ðŸ˜±\",\" Í â€Œ ï»¿\",\"ÿ\",\"x = = x\",\"*\"]\n",
    "for letter in replace_list:\n",
    "    df['Text'] = df['Text'].str.replace(letter, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b184135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishi Kapadia\\AppData\\Local\\Temp\\ipykernel_20240\\1837515156.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Text'] = df['Text'].str.replace(letter, '')\n"
     ]
    }
   ],
   "source": [
    "email_replace_list = [\"Subject:\",\"cc:\"]\n",
    "for letter in email_replace_list:\n",
    "    df['Text'] = df['Text'].str.replace(letter, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92acfc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishi Kapadia\\AppData\\Local\\Temp\\ipykernel_20240\\2202711307.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['preprocessed_text'] = df['Text'].apply(lambda x: preprocessing_text(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       In The Simpsons Movie release July 2007 name b...\n",
       "1       professional logo work company image start vis...\n",
       "2       get baby diaper bill pay year family could def...\n",
       "3       uuseful attache save medlcations 70 pharmsho f...\n",
       "4       model effort houston christian spring fall win...\n",
       "                              ...                        \n",
       "2879    Get official ENGLAND poly ringtone colour flag...\n",
       "2881    perfect logo charset koi 8 r thinking breathe ...\n",
       "2882    save money get oem software need software pc v...\n",
       "2883                                            Dear Call\n",
       "2884    logo stationer website design much lt really h...\n",
       "Name: preprocessed_text, Length: 2790, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = nltk.word_tokenize(text)\n",
    "\n",
    "        filtered_words = []\n",
    "        for word in text:\n",
    "            if word.isalnum():\n",
    "                filtered_words.append(word)\n",
    "\n",
    "        text = filtered_words[:]\n",
    "        \n",
    "        lemmatized_words= []\n",
    "        for word, pos in nltk.pos_tag(text):\n",
    "            if word.isalnum() and word not in stopwords.words('english') and word not in string.punctuation:\n",
    "                # Get the first letter of the POS tag\n",
    "                pos = pos[0].lower()\n",
    "                # Consider only adjectives, nouns, and verbs for lemmatization\n",
    "                if pos in {'a', 'n', 'v'}:\n",
    "                    lemmatized_words.append(lemmatizer.lemmatize(word, pos))\n",
    "                else:\n",
    "                    lemmatized_words.append(word)\n",
    "\n",
    "        return \" \".join(lemmatized_words)\n",
    "    else:\n",
    "        # Convert non-string types to string\n",
    "        return str(text)\n",
    "\n",
    "# Apply the modified transform_text2 function using lambda to the 'Text' column\n",
    "df['preprocessed_text'] = df['Text'].apply(lambda x: preprocessing_text(x))\n",
    "df['preprocessed_text']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
