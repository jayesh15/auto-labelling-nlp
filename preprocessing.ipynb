{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293756ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b3d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vedant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vedant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b414eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In The Simpsons Movie released in July 2007 na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>professional logo for you now  working on you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get your babies diapers bill paid for , for a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very uuseful  attache how to save on your med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model effort in houston  christian ,  our spr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8362 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Message\n",
       "0     In The Simpsons Movie released in July 2007 na...\n",
       "1      professional logo for you now  working on you...\n",
       "2      get your babies diapers bill paid for , for a...\n",
       "3      very uuseful  attache how to save on your med...\n",
       "4      model effort in houston  christian ,  our spr...\n",
       "...                                                 ...\n",
       "5567  This is the 2nd time we have tried 2 contact u...\n",
       "5568               Will ü b going to esplanade fr home?\n",
       "5569  Pity, * was in mood for that. So...any other s...\n",
       "5570  The guy did some bitching but I acted like i'd...\n",
       "5571                         Rofl. Its true to its name\n",
       "\n",
       "[8362 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the excel data\n",
    "#df = pd.read_excel(r\"C:\\College\\sem6\\NLP\\project\\text_dataset.xlsx\")\n",
    "df = pd.read_excel(r\"C:\\Users\\Vedant\\OneDrive\\Desktop\\College\\TY\\SEM 6\\NLP\\preprocessed_text.xlsx\")\n",
    "df1 = pd.read_csv(r\"C:\\Users\\Vedant\\Downloads\\mail_data.csv\")\n",
    "df = pd.concat([df,df1])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41132416",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b454d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8362 entries, 0 to 5571\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Message  8362 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 130.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "654bbb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values and remove\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbd9184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7291, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicate values and remove\n",
    "print(df.duplicated().sum())\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b12c43",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680f4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_17736\\221389072.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Message'] = df['Message'].str.replace(letter, '')\n"
     ]
    }
   ],
   "source": [
    "# replace unnecessary letters/words\n",
    "replace_list = [\" &lt;#&gt;\",\"Ã\",\"&gt;\",\"\\\\n\",\"\\\\t\",\"\\\\r\",\"â\",\"€\",\"™\",\"ð\",\"Ÿ\",\"ðŸ‘\",\"$\",\"â€™ll\",\"ƒ\",\"¢\",\"â€ƒ\",\"â€¢\",\"Â§\",\"§\",\"Â\",\"Ã¼\",\"Ã\",\"¼\",\"º\",\"œ\",\"˜\",\"£\",\"â€“\",\"â€œ\",\"&lt;#&gt;\",\"â€Œ\",\"ðŸŽ\",\"ð\",\"Ÿ\",\"Ž\",\"Í\",\"â€Œ ï»¿ Í\",\"ï»¿\",\"ðŸ”¨\",\"ðŸ¤©\",\"©\",\"¤\",\"±\",\"ðŸ˜±\",\"ðŸ˜±\",\" Í â€Œ ï»¿\",\"ÿ\",\"x = = x\",\"*\"]\n",
    "for letter in replace_list:\n",
    "    df['Message'] = df['Message'].str.replace(letter, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b184135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_17736\\2984804244.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Message'] = df['Message'].str.replace(letter, '')\n"
     ]
    }
   ],
   "source": [
    "email_replace_list = [\"Subject:\",\"cc:\"]\n",
    "for letter in email_replace_list:\n",
    "    df['Message'] = df['Message'].str.replace(letter, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92acfc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vedant\\AppData\\Local\\Temp\\ipykernel_17736\\1090032615.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['preprocessed_text'] = df['Message'].apply(lambda x: preprocessing_text(x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       In The Simpsons Movie release July 2007 name b...\n",
       "1       professional logo work company image start vis...\n",
       "2       get baby diaper bill pay year family could def...\n",
       "3       uuseful attache save medlcations 70 pharmsho f...\n",
       "4       model effort houston christian spring fall win...\n",
       "                              ...                        \n",
       "5567    This 2nd time try 2 contact U 750 Pound prize ...\n",
       "5568                        Will ü b go esplanade fr home\n",
       "5569                              Pity mood So suggestion\n",
       "5570    The guy bitching I act like interested buy som...\n",
       "5571                                   Rofl Its true name\n",
       "Name: preprocessed_text, Length: 7291, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = nltk.word_tokenize(text)\n",
    "\n",
    "        filtered_words = []\n",
    "        for word in text:\n",
    "            if word.isalnum():\n",
    "                filtered_words.append(word)\n",
    "\n",
    "        text = filtered_words[:]\n",
    "        \n",
    "        lemmatized_words= []\n",
    "        for word, pos in nltk.pos_tag(text):\n",
    "            if word.isalnum() and word not in stopwords.words('english') and word not in string.punctuation:\n",
    "                # Get the first letter of the POS tag\n",
    "                pos = pos[0].lower()\n",
    "                # Consider only adjectives, nouns, and verbs for lemmatization\n",
    "                if pos in {'a', 'n', 'v'}:\n",
    "                    lemmatized_words.append(lemmatizer.lemmatize(word, pos))\n",
    "                else:\n",
    "                    lemmatized_words.append(word)\n",
    "\n",
    "        return \" \".join(lemmatized_words)\n",
    "    else:\n",
    "        # Convert non-string types to string\n",
    "        return str(text)\n",
    "\n",
    "# Apply the modified transform_text2 function using lambda to the 'Text' column\n",
    "df['preprocessed_text'] = df['Message'].apply(lambda x: preprocessing_text(x))\n",
    "df['preprocessed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55709a",
   "metadata": {},
   "source": [
    "ZERO-SHOT CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "320120db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the classes\n",
    "classes_verbalized = [\"politics\", \"economy\", \"entertainment\", \"environment\", \"sports\", \"finance\",\"spam\",\"personal\"]\n",
    "\n",
    "# Initialize the zero-shot classification pipeline\n",
    "zeroshot_classifier = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/deberta-v3-large-zeroshot-v1.1-all-33\")\n",
    "\n",
    "# Create empty lists to store results\n",
    "predicted_categories = []\n",
    "\n",
    "# Iterate over each text in the DataFrame\n",
    "for text in df[\"preprocessed_text\"]:\n",
    "    # Perform zero-shot classification\n",
    "    output = zeroshot_classifier(text, classes_verbalized, multi_label=False)\n",
    "    # Get the index of the label with the highest score\n",
    "    max_score_index = output[\"scores\"].index(max(output[\"scores\"]))\n",
    "    # Get the label with the highest score\n",
    "    predicted_label = output[\"labels\"][max_score_index]\n",
    "    \n",
    "    # Append the predicted category to the list\n",
    "    predicted_categories.append(predicted_label)\n",
    "\n",
    "# Add the predicted categories as a new column to the DataFrame\n",
    "df[\"category\"] = predicted_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f0629",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97c0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd69ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a4ef62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\vedant\\anaconda3\\lib\\site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vedant\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18489be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c3dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed254bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317abcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c55419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
