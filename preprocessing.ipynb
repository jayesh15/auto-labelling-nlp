{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "293756ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b414eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read files for merge\n",
    "df1 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 01.xlsx\")\n",
    "df2 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 02.xlsx\")\n",
    "df3 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 03.xlsx\")\n",
    "df4 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 04.xlsx\")\n",
    "df5 = pd.read_excel(r\"C:\\Users\\karan\\Downloads\\Data - 05.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6eb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge files\n",
    "df_merge = pd.concat([df1,df2,df3,df4,df5])\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41132416",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83158e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b454d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654bbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values and remove\n",
    "print(df_merge.isnull().sum())\n",
    "df_merge.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbd9184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate values and remove\n",
    "print(df_merge.duplicated().sum())\n",
    "df_merge = df_merge.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73934111",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b12c43",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f4e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace unnecessary letters/words\n",
    "replace_list = [\"\\\\n\",\"\\\\t\",\"\\\\r\",\"â\",\"€\",\"™\",\"ð\",\"Ÿ\",\"ðŸ‘\",\"$\",\"â€™ll\",\"ƒ\",\"¢\",\"â€ƒ\",\"â€¢\",\"Â§\",\"§\",\"Â\",\"Ã¼\",\"Ã\",\"¼\",\"º\",\"œ\",\"˜\",\"£\",\"â€“\",\"â€œ\",\"&lt;#&gt;\",\"â€Œ\",\"ðŸŽ\",\"ð\",\"Ÿ\",\"Ž\",\"Í\",\"â€Œ ï»¿ Í\",\"ï»¿\",\"ðŸ”¨\",\"ðŸ¤©\",\"©\",\"¤\",\"±\",\"ðŸ˜±\",\"ðŸ˜±\",\" Í â€Œ ï»¿\",\"ÿ\" ]\n",
    "for letter in replace_list:\n",
    "    df_merge['Text'] = df_merge['Text'].str.replace(letter, '')\n",
    "print(df_merge.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9608b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for preprocessing\n",
    "def preprocessing(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text\n",
    "        text = nltk.word_tokenize(text)\n",
    "\n",
    "        filtered_words = []\n",
    "        for word in text:\n",
    "            if word.isalnum():\n",
    "                filtered_words.append(word)\n",
    "\n",
    "        text = filtered_words[:]\n",
    "        filtered_words.clear()\n",
    "\n",
    "        for word in text:\n",
    "            if word not in stopwords.words('english') and word not in string.punctuation:\n",
    "                filtered_words.append(word)\n",
    "\n",
    "        text = filtered_words[:]\n",
    "        filtered_words.clear()\n",
    "\n",
    "        for word in text:\n",
    "            filtered_words.append(ps.stem(word))\n",
    "\n",
    "        return \" \".join(filtered_words)\n",
    "    else:\n",
    "        # convert to string\n",
    "        return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50115f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
