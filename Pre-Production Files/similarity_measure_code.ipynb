{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d917408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d317ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between sentence 1 and sentence 2: 0.7470758\n"
     ]
    }
   ],
   "source": [
    "#Word2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def calculate_word2vec_cosine_similarity(sentence1, sentence2, min_count=1):\n",
    "    # Tokenize the sentences into words\n",
    "    tokenized_sentence1 = sentence1.split()\n",
    "    tokenized_sentence2 = sentence2.split()\n",
    "\n",
    "    # Train a Word2Vec model on the tokenized sentences\n",
    "    sentences = [tokenized_sentence1, tokenized_sentence2]\n",
    "    model = Word2Vec(sentences, min_count=min_count)\n",
    "\n",
    "    # Get the Word2Vec embeddings for each word in the sentences\n",
    "    word_vectors = []\n",
    "    for tokenized_sentence in sentences:\n",
    "        sentence_vectors = []\n",
    "        for word in tokenized_sentence:\n",
    "            # Skip words not in the vocabulary\n",
    "            if word in model.wv:\n",
    "                sentence_vectors.append(model.wv[word])\n",
    "        # Calculate the mean vector for the sentence\n",
    "        if sentence_vectors:\n",
    "            sentence_vector = np.mean(sentence_vectors, axis=0)\n",
    "            word_vectors.append(sentence_vector)\n",
    "\n",
    "    # Calculate cosine similarity between the Word2Vec embeddings of the sentences\n",
    "    cosine_similarity_score = cosine_similarity([word_vectors[0]], [word_vectors[1]])\n",
    "\n",
    "    return cosine_similarity_score[0][0]\n",
    "\n",
    "# Example usage:\n",
    "sentence1 = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human窶田omputer interaction.\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. NLP is used to apply algorithms to human language to enable computers to understand and interpret human language and extract meaning from text.\"\n",
    "similarity_score = calculate_word2vec_cosine_similarity(sentence1, sentence2)\n",
    "print(\"Cosine Similarity between sentence 1 and sentence 2:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "47df0a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Cosine Similarity between sentence 1 and sentence 2: 0.6625278058650176\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_tfidf_cosine_similarity(sentence1, sentence2):\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform([sentence1, sentence2])\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# Example usage:\n",
    "sentence1 = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human窶田omputer interaction..\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. NLP is used to apply algorithms to human language to enable computers to understand and interpret human language and extract meaning from text\"\n",
    "similarity_score = calculate_tfidf_cosine_similarity(sentence1, sentence2)\n",
    "print(\"TF-IDF Cosine Similarity between sentence 1 and sentence 2:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abd855d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec Cosine Similarity between sentence 1 and sentence 2: 0.96662915\n"
     ]
    }
   ],
   "source": [
    "#Doc2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_doc2vec_cosine_similarity(sentence1, sentence2):\n",
    "    tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate([sentence1, sentence2])]\n",
    "    model = Doc2Vec(vector_size=100, min_count=1, epochs=50)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    vector1 = model.infer_vector(sentence1.split())\n",
    "    vector2 = model.infer_vector(sentence2.split())\n",
    "    cosine_sim = cosine_similarity([vector1], [vector2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# Example usage:\n",
    "sentence1 = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human窶田omputer interaction.\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. NLP is used to apply algorithms to human language to enable computers to understand and interpret human language and extract meaning from text\"\n",
    "similarity_score = calculate_doc2vec_cosine_similarity(sentence1, sentence2)\n",
    "print(\"Doc2Vec Cosine Similarity between sentence 1 and sentence 2:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fbc74dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Transformers Cosine Similarity between sentence 1 and sentence 2: 0.95967066\n"
     ]
    }
   ],
   "source": [
    "#Sentence Transformer\n",
    "#!pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_sentence_transformers_cosine_similarity(sentence1, sentence2):\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings = model.encode([sentence1, sentence2], convert_to_tensor=True)\n",
    "    cosine_sim = cosine_similarity(embeddings[0].unsqueeze(0), embeddings[1].unsqueeze(0))\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# Example usage:\n",
    "sentence1 = \"Natural language processing (NLP) is a field of computer science, artificial intelligence, and computational linguistics concerned with the interactions between computers and human (natural) languages. As such, NLP is related to the area of human窶田omputer interaction..\"\n",
    "sentence2 = \"Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human (natural) languages. NLP is used to apply algorithms to human language to enable computers to understand and interpret human language and extract meaning from text\"\n",
    "similarity_score = calculate_sentence_transformers_cosine_similarity(sentence1, sentence2)\n",
    "print(\"Sentence Transformers Cosine Similarity between sentence 1 and sentence 2:\", similarity_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
